{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMlS3ad5HRtWiN0S44a7VBx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Install Dependencies"],"metadata":{"id":"YJDK4TzDOlZo"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"akNRsO3wNoQ7","executionInfo":{"status":"ok","timestamp":1744884611379,"user_tz":-330,"elapsed":7922,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"c98962eb-dbeb-4e49-deb2-4e8f063ed4ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q -U google-generativeai"]},{"cell_type":"markdown","source":["# Import packages"],"metadata":{"id":"AFrGVe9mOqr9"}},{"cell_type":"code","source":["import google.generativeai as genai\n","import pathlib\n","import textwrap\n","from IPython.display import display\n","from IPython.display import Markdown"],"metadata":{"id":"2tvFxKOCOhjw","executionInfo":{"status":"ok","timestamp":1744884731599,"user_tz":-330,"elapsed":1298,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def to_markdown(text):\n","  text = text.replace('•',' *')\n","  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n","\n","#Example usage:\n","input_text = \"This is a • simple text with bullet points.\"\n","result = to_markdown(input_text)\n","display(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":62},"id":"8IrYXTQTPAiH","executionInfo":{"status":"ok","timestamp":1744885220009,"user_tz":-330,"elapsed":72,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"652b14b0-01d4-4d05-b45e-5781953d0b04"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"> This is a  * simple text with bullet points."},"metadata":{}}]},{"cell_type":"code","source":["# Used to securely store your API key\n","from google.colab import userdata"],"metadata":{"id":"ZEiKb6tuQ4Eg","executionInfo":{"status":"ok","timestamp":1744885356694,"user_tz":-330,"elapsed":44,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"],"metadata":{"id":"bbpjd31HRSZk","executionInfo":{"status":"ok","timestamp":1744885397924,"user_tz":-330,"elapsed":1635,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["genai.configure(api_key=GOOGLE_API_KEY)"],"metadata":{"id":"K5Q5GOcKRjIG","executionInfo":{"status":"ok","timestamp":1744885455470,"user_tz":-330,"elapsed":16,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["for models in genai.list_models():\n","  print(models)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tWoVPBP7Rxkk","executionInfo":{"status":"ok","timestamp":1744885486682,"user_tz":-330,"elapsed":2465,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"7a24df8b-727c-465a-8b96-fb3646ae37aa"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model(name='models/chat-bison-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='PaLM 2 Chat (Legacy)',\n","      description='A legacy text-only model optimized for chat conversations',\n","      input_token_limit=4096,\n","      output_token_limit=1024,\n","      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n","      temperature=0.25,\n","      max_temperature=None,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/text-bison-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='PaLM 2 (Legacy)',\n","      description='A legacy model that understands text and generates text as an output',\n","      input_token_limit=8196,\n","      output_token_limit=1024,\n","      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n","      temperature=0.7,\n","      max_temperature=None,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/embedding-gecko-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Embedding Gecko',\n","      description='Obtain a distributed representation of a text.',\n","      input_token_limit=1024,\n","      output_token_limit=1,\n","      supported_generation_methods=['embedText', 'countTextTokens'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/gemini-1.0-pro-vision-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro Vision',\n","      description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n","                   'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n","                   'Move to a newer Gemini version.'),\n","      input_token_limit=12288,\n","      output_token_limit=4096,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.4,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=32)\n","Model(name='models/gemini-pro-vision',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro Vision',\n","      description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n","                   'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n","                   'Move to a newer Gemini version.'),\n","      input_token_limit=12288,\n","      output_token_limit=4096,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.4,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=32)\n","Model(name='models/gemini-1.5-pro-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Pro Latest',\n","      description=('Alias that points to the most recent production (non-experimental) release '\n","                   'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n","                   'million tokens.'),\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-pro-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Pro 001',\n","      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n","                   'supports up to 2 million tokens, released in May of 2024.'),\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-pro-002',\n","      base_model_id='',\n","      version='002',\n","      display_name='Gemini 1.5 Pro 002',\n","      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n","                   'supports up to 2 million tokens, released in September of 2024.'),\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-pro',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Pro',\n","      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n","                   'supports up to 2 million tokens, released in May of 2024.'),\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash Latest',\n","      description=('Alias that points to the most recent production (non-experimental) release '\n","                   'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n","                   'across diverse tasks.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 001',\n","      description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n","                   'for scaling across diverse tasks, released in May of 2024.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-flash-001-tuning',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 001 Tuning',\n","      description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n","                   'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n","      input_token_limit=16384,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-flash',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash',\n","      description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n","                   'fast and versatile multimodal model for scaling across diverse tasks.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-002',\n","      base_model_id='',\n","      version='002',\n","      display_name='Gemini 1.5 Flash 002',\n","      description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n","                   'for scaling across diverse tasks, released in September of 2024.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash-8B',\n","      description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n","                   'Flash model, released in October of 2024.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash-8B 001',\n","      description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n","                   'Flash model, released in October of 2024.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash-8B Latest',\n","      description=('Alias that points to the most recent production (non-experimental) release '\n","                   'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n","                   'released in October of 2024.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-exp-0827',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 8B Experimental 0827',\n","      description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n","                   'smallest and most cost effective Flash model. Replaced by '\n","                   'Gemini-1.5-flash-8b-001 (stable).'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-exp-0924',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 8B Experimental 0924',\n","      description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n","                   'smallest and most cost effective Flash model. Replaced by '\n","                   'Gemini-1.5-flash-8b-001 (stable).'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-2.5-pro-exp-03-25',\n","      base_model_id='',\n","      version='2.5-exp-03-25',\n","      display_name='Gemini 2.5 Pro Experimental 03-25',\n","      description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n","      input_token_limit=1048576,\n","      output_token_limit=65536,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-2.5-pro-preview-03-25',\n","      base_model_id='',\n","      version='2.5-preview-03-25',\n","      display_name='Gemini 2.5 Pro Preview 03-25',\n","      description='Gemini 2.5 Pro Preview 03-25',\n","      input_token_limit=1048576,\n","      output_token_limit=65536,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-2.0-flash-exp',\n","      base_model_id='',\n","      version='2.0',\n","      display_name='Gemini 2.0 Flash Experimental',\n","      description='Gemini 2.0 Flash Experimental',\n","      input_token_limit=1048576,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-2.0-flash',\n","      base_model_id='',\n","      version='2.0',\n","      display_name='Gemini 2.0 Flash',\n","      description='Gemini 2.0 Flash',\n","      input_token_limit=1048576,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-2.0-flash-001',\n","      base_model_id='',\n","      version='2.0',\n","      display_name='Gemini 2.0 Flash 001',\n","      description=('Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model '\n","                   'for scaling across diverse tasks, released in January of 2025.'),\n","      input_token_limit=1048576,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-2.0-flash-exp-image-generation',\n","      base_model_id='',\n","      version='2.0',\n","      display_name='Gemini 2.0 Flash (Image Generation) Experimental',\n","      description='Gemini 2.0 Flash (Image Generation) Experimental',\n","      input_token_limit=1048576,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-2.0-flash-lite-001',\n","      base_model_id='',\n","      version='2.0',\n","      display_name='Gemini 2.0 Flash-Lite 001',\n","      description='Stable version of Gemini 2.0 Flash Lite',\n","      input_token_limit=1048576,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-2.0-flash-lite',\n","      base_model_id='',\n","      version='2.0',\n","      display_name='Gemini 2.0 Flash-Lite',\n","      description='Gemini 2.0 Flash-Lite',\n","      input_token_limit=1048576,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-2.0-flash-lite-preview-02-05',\n","      base_model_id='',\n","      version='preview-02-05',\n","      display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n","      description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite',\n","      input_token_limit=1048576,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-2.0-flash-lite-preview',\n","      base_model_id='',\n","      version='preview-02-05',\n","      display_name='Gemini 2.0 Flash-Lite Preview',\n","      description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite',\n","      input_token_limit=1048576,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-2.0-pro-exp',\n","      base_model_id='',\n","      version='2.5-exp-03-25',\n","      display_name='Gemini 2.0 Pro Experimental',\n","      description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n","      input_token_limit=1048576,\n","      output_token_limit=65536,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-2.0-pro-exp-02-05',\n","      base_model_id='',\n","      version='2.5-exp-03-25',\n","      display_name='Gemini 2.0 Pro Experimental 02-05',\n","      description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n","      input_token_limit=1048576,\n","      output_token_limit=65536,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-exp-1206',\n","      base_model_id='',\n","      version='2.5-exp-03-25',\n","      display_name='Gemini Experimental 1206',\n","      description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n","      input_token_limit=1048576,\n","      output_token_limit=65536,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-2.0-flash-thinking-exp-01-21',\n","      base_model_id='',\n","      version='2.0-exp-01-21',\n","      display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n","      description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n","      input_token_limit=1048576,\n","      output_token_limit=65536,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.7,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-2.0-flash-thinking-exp',\n","      base_model_id='',\n","      version='2.0-exp-01-21',\n","      display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n","      description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n","      input_token_limit=1048576,\n","      output_token_limit=65536,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.7,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n","      base_model_id='',\n","      version='2.0',\n","      display_name='Gemini 2.0 Flash Thinking Experimental',\n","      description='Gemini 2.0 Flash Thinking Experimental',\n","      input_token_limit=1048576,\n","      output_token_limit=65536,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.7,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/learnlm-1.5-pro-experimental',\n","      base_model_id='',\n","      version='001',\n","      display_name='LearnLM 1.5 Pro Experimental',\n","      description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n","                   'mid-size multimodal model that supports up to 2 million tokens.'),\n","      input_token_limit=32767,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/learnlm-2.0-flash-experimental',\n","      base_model_id='',\n","      version='2.0',\n","      display_name='LearnLM 2.0 Flash Experimental',\n","      description='LearnLM 2.0 Flash Experimental',\n","      input_token_limit=1048576,\n","      output_token_limit=32768,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemma-3-1b-it',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemma 3 1B',\n","      description='',\n","      input_token_limit=32768,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=None,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemma-3-4b-it',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemma 3 4B',\n","      description='',\n","      input_token_limit=32768,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=None,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemma-3-12b-it',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemma 3 12B',\n","      description='',\n","      input_token_limit=32768,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=None,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemma-3-27b-it',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemma 3 27B',\n","      description='',\n","      input_token_limit=131072,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=None,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/embedding-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Embedding 001',\n","      description='Obtain a distributed representation of a text.',\n","      input_token_limit=2048,\n","      output_token_limit=1,\n","      supported_generation_methods=['embedContent'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/text-embedding-004',\n","      base_model_id='',\n","      version='004',\n","      display_name='Text Embedding 004',\n","      description='Obtain a distributed representation of a text.',\n","      input_token_limit=2048,\n","      output_token_limit=1,\n","      supported_generation_methods=['embedContent'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/gemini-embedding-exp-03-07',\n","      base_model_id='',\n","      version='exp-03-07',\n","      display_name='Gemini Embedding Experimental 03-07',\n","      description='Obtain a distributed representation of a text.',\n","      input_token_limit=8192,\n","      output_token_limit=1,\n","      supported_generation_methods=['embedContent', 'countTextTokens'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/gemini-embedding-exp',\n","      base_model_id='',\n","      version='exp-03-07',\n","      display_name='Gemini Embedding Experimental',\n","      description='Obtain a distributed representation of a text.',\n","      input_token_limit=8192,\n","      output_token_limit=1,\n","      supported_generation_methods=['embedContent', 'countTextTokens'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/aqa',\n","      base_model_id='',\n","      version='001',\n","      display_name='Model that performs Attributed Question Answering.',\n","      description=('Model trained to return answers to questions that are grounded in provided '\n","                   'sources, along with estimating answerable probability.'),\n","      input_token_limit=7168,\n","      output_token_limit=1024,\n","      supported_generation_methods=['generateAnswer'],\n","      temperature=0.2,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=40)\n","Model(name='models/imagen-3.0-generate-002',\n","      base_model_id='',\n","      version='002',\n","      display_name='Imagen 3.0 002 model',\n","      description='Vertex served Imagen 3.0 002 model',\n","      input_token_limit=480,\n","      output_token_limit=8192,\n","      supported_generation_methods=['predict'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/gemini-2.0-flash-live-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 2.0 Flash 001',\n","      description='Gemini 2.0 Flash 001',\n","      input_token_limit=131072,\n","      output_token_limit=8192,\n","      supported_generation_methods=['bidiGenerateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n"]}]},{"cell_type":"code","source":["for models in genai.list_models():\n","  if 'generateContent' in models.supported_generation_methods:\n","    print(models.name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"fGZy-If_R4mE","executionInfo":{"status":"ok","timestamp":1744885562817,"user_tz":-330,"elapsed":2009,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"2ed392e5-4ac8-4f9c-a34f-217564de522c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["models/gemini-1.0-pro-vision-latest\n","models/gemini-pro-vision\n","models/gemini-1.5-pro-latest\n","models/gemini-1.5-pro-001\n","models/gemini-1.5-pro-002\n","models/gemini-1.5-pro\n","models/gemini-1.5-flash-latest\n","models/gemini-1.5-flash-001\n","models/gemini-1.5-flash-001-tuning\n","models/gemini-1.5-flash\n","models/gemini-1.5-flash-002\n","models/gemini-1.5-flash-8b\n","models/gemini-1.5-flash-8b-001\n","models/gemini-1.5-flash-8b-latest\n","models/gemini-1.5-flash-8b-exp-0827\n","models/gemini-1.5-flash-8b-exp-0924\n","models/gemini-2.5-pro-exp-03-25\n","models/gemini-2.5-pro-preview-03-25\n","models/gemini-2.0-flash-exp\n","models/gemini-2.0-flash\n","models/gemini-2.0-flash-001\n","models/gemini-2.0-flash-exp-image-generation\n","models/gemini-2.0-flash-lite-001\n","models/gemini-2.0-flash-lite\n","models/gemini-2.0-flash-lite-preview-02-05\n","models/gemini-2.0-flash-lite-preview\n","models/gemini-2.0-pro-exp\n","models/gemini-2.0-pro-exp-02-05\n","models/gemini-exp-1206\n","models/gemini-2.0-flash-thinking-exp-01-21\n","models/gemini-2.0-flash-thinking-exp\n","models/gemini-2.0-flash-thinking-exp-1219\n","models/learnlm-1.5-pro-experimental\n","models/learnlm-2.0-flash-experimental\n","models/gemma-3-1b-it\n","models/gemma-3-4b-it\n","models/gemma-3-12b-it\n","models/gemma-3-27b-it\n"]}]},{"cell_type":"markdown","source":["# Generate text from text inputs"],"metadata":{"id":"hB_XB_45SeZv"}},{"cell_type":"code","source":["model = genai.GenerativeModel('models/gemini-1.5-pro-001')"],"metadata":{"id":"PYfxjdTdSLSn","executionInfo":{"status":"ok","timestamp":1744885863137,"user_tz":-330,"elapsed":7,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["%%time\n","response = model.generate_content(\"What is the meaning of life?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"zsSTG_G1SrVx","executionInfo":{"status":"ok","timestamp":1744885879897,"user_tz":-330,"elapsed":8186,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"8eb7f138-8f67-42be-ad19-70de210358d1"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 46.9 ms, sys: 10.7 ms, total: 57.6 ms\n","Wall time: 8.15 s\n"]}]},{"cell_type":"code","source":["to_markdown(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"FPl1TYJCS6_b","executionInfo":{"status":"ok","timestamp":1744886337012,"user_tz":-330,"elapsed":54,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"92663386-9b6f-4403-aeec-eb7b46afd947"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"> As a large language model, I don't have personal beliefs or experiences to draw on. I can't tell you the meaning of life, because ultimately, that's a question each individual has to answer for themselves. \n> \n> However, I can offer some perspectives that might be helpful in your own exploration:\n> \n> * **Purpose & Meaning:** Some find meaning in serving a greater purpose, whether it's through religion, community work, or fighting for a cause they believe in. \n> * **Relationships & Love:** Connecting with others, building loving relationships, and experiencing the joys of family and friendship provide meaning for many.\n> * **Growth & Learning:**  The pursuit of knowledge, personal development, and expanding one's understanding of the world can be deeply fulfilling.\n> * **Creativity & Expression:**  Expressing oneself through art, music, writing, or any other creative outlet can bring joy and a sense of accomplishment. \n> * **Contribution & Legacy:**  Leaving the world a better place than you found it, whether through raising children, making a scientific discovery, or simply being kind to others, can give life meaning. \n> \n> Ultimately, the meaning of life is not a universal answer, but a journey of self-discovery. It's about exploring your values, passions, and what brings you joy and fulfillment. \n> \n> What matters most is that you find your own answer, one that resonates with you and guides you in living a fulfilling life. \n"},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["response.candidates"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jptlY1XTVBYj","executionInfo":{"status":"ok","timestamp":1744886422319,"user_tz":-330,"elapsed":27,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"f2d2e3b4-76bf-4a47-a932-f9571edbaecd"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[content {\n","  parts {\n","    text: \"As a large language model, I don\\'t have personal beliefs or experiences to draw on. I can\\'t tell you the meaning of life, because ultimately, that\\'s a question each individual has to answer for themselves. \\n\\nHowever, I can offer some perspectives that might be helpful in your own exploration:\\n\\n* **Purpose & Meaning:** Some find meaning in serving a greater purpose, whether it\\'s through religion, community work, or fighting for a cause they believe in. \\n* **Relationships & Love:** Connecting with others, building loving relationships, and experiencing the joys of family and friendship provide meaning for many.\\n* **Growth & Learning:**  The pursuit of knowledge, personal development, and expanding one\\'s understanding of the world can be deeply fulfilling.\\n* **Creativity & Expression:**  Expressing oneself through art, music, writing, or any other creative outlet can bring joy and a sense of accomplishment. \\n* **Contribution & Legacy:**  Leaving the world a better place than you found it, whether through raising children, making a scientific discovery, or simply being kind to others, can give life meaning. \\n\\nUltimately, the meaning of life is not a universal answer, but a journey of self-discovery. It\\'s about exploring your values, passions, and what brings you joy and fulfillment. \\n\\nWhat matters most is that you find your own answer, one that resonates with you and guides you in living a fulfilling life. \\n\"\n","  }\n","  role: \"model\"\n","}\n","finish_reason: STOP\n","index: 0\n","safety_ratings {\n","  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n","  probability: NEGLIGIBLE\n","}\n","safety_ratings {\n","  category: HARM_CATEGORY_HATE_SPEECH\n","  probability: NEGLIGIBLE\n","}\n","safety_ratings {\n","  category: HARM_CATEGORY_HARASSMENT\n","  probability: NEGLIGIBLE\n","}\n","safety_ratings {\n","  category: HARM_CATEGORY_DANGEROUS_CONTENT\n","  probability: NEGLIGIBLE\n","}\n","]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["response.parts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ca9gMIg8VX9g","executionInfo":{"status":"ok","timestamp":1744886465237,"user_tz":-330,"elapsed":5,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"054f10c4-210c-4b3c-b573-56ab7c4cf3fc"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[text: \"As a large language model, I don\\'t have personal beliefs or experiences to draw on. I can\\'t tell you the meaning of life, because ultimately, that\\'s a question each individual has to answer for themselves. \\n\\nHowever, I can offer some perspectives that might be helpful in your own exploration:\\n\\n* **Purpose & Meaning:** Some find meaning in serving a greater purpose, whether it\\'s through religion, community work, or fighting for a cause they believe in. \\n* **Relationships & Love:** Connecting with others, building loving relationships, and experiencing the joys of family and friendship provide meaning for many.\\n* **Growth & Learning:**  The pursuit of knowledge, personal development, and expanding one\\'s understanding of the world can be deeply fulfilling.\\n* **Creativity & Expression:**  Expressing oneself through art, music, writing, or any other creative outlet can bring joy and a sense of accomplishment. \\n* **Contribution & Legacy:**  Leaving the world a better place than you found it, whether through raising children, making a scientific discovery, or simply being kind to others, can give life meaning. \\n\\nUltimately, the meaning of life is not a universal answer, but a journey of self-discovery. It\\'s about exploring your values, passions, and what brings you joy and fulfillment. \\n\\nWhat matters most is that you find your own answer, one that resonates with you and guides you in living a fulfilling life. \\n\"\n","]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["%%time\n","response = model.generate_content(\"What is the meaning of life\", stream=True)\n","for chunk in response:\n","  print(chunk.text)\n","  print('_'*80)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"3zE6ywh_VoGN","executionInfo":{"status":"ok","timestamp":1744886903315,"user_tz":-330,"elapsed":306441,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"e03c43e5-87eb-4104-c545-38a6c9f7096c"},"execution_count":21,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewrite_stream_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                     iterator = self._client.stream_generate_content(\n\u001b[0m\u001b[1;32m    326\u001b[0m                         \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                         \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mstream_generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1144\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             response = (\n\u001b[0;32m-> 1318\u001b[0;31m                 GenerativeServiceRestTransport._StreamGenerateContent._get_response(\n\u001b[0m\u001b[1;32m   1319\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m                     \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(host, metadata, query_params, session, timeout, transcoded_request, body)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             response = getattr(session, method)(\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    538\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["!curl -o image.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTsTRPiuWIPF","executionInfo":{"status":"ok","timestamp":1744887174497,"user_tz":-330,"elapsed":108,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"4e66ade1-9c03-4b20-9768-1a7805ee1a7e"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  405k  100  405k    0     0  6433k      0 --:--:-- --:--:-- --:--:-- 6533k\n"]}]},{"cell_type":"code","source":["!curl -o image2.jpg https://images.pexels.com/photos/414612/pexels-photo-414612.jpeg?cs=srgb&dl=pexels-james-wheeler-414612.jpg&fm=jpg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTROwvxBXRUM","executionInfo":{"status":"ok","timestamp":1744887176859,"user_tz":-330,"elapsed":281,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"2010417a-9e8b-4b61-ba0c-108f54311535"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 1499k  100 1499k    0     0  5761k      0 --:--:-- --:--:-- --:--:-- 5767k\n"]}]},{"cell_type":"code","source":["import PIL.Image\n","img = PIL.Image.open('image.jpg')\n","img"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":959,"output_embedded_package_id":"1andsUKvtIQ-9XVtgxVb2a3pbgAaYL-Vf"},"id":"GlbvQ31xX61a","executionInfo":{"status":"ok","timestamp":1744887180777,"user_tz":-330,"elapsed":1488,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"e4f9a9ee-b2ad-44d8-fd8e-cec6e3c2b8d6"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["import PIL.Image\n","img = PIL.Image.open('image2.jpg')\n","img"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1hZjlCN97r6o4SgAaY1YO54hc8H25V0Jq"},"id":"LyEJiJnPYMoo","executionInfo":{"status":"ok","timestamp":1744887198513,"user_tz":-330,"elapsed":8133,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"87cd1eec-a30c-40da-d39f-d86f25b86e21"},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["model2 = genai.GenerativeModel('gemini-1.5-flash')"],"metadata":{"id":"hACxVlHPYZIv","executionInfo":{"status":"ok","timestamp":1744887377929,"user_tz":-330,"elapsed":2,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["response = model2.generate_content(img)"],"metadata":{"id":"Gjp84-mqYsPf","executionInfo":{"status":"ok","timestamp":1744887387216,"user_tz":-330,"elapsed":8383,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["response.text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":123},"id":"pzGKpWq0Yxd7","executionInfo":{"status":"ok","timestamp":1744887387224,"user_tz":-330,"elapsed":5,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"5710ae90-1b59-4a5e-c3e6-fa5fd3f231a8"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Here's a description of the image:\\n\\nThe photograph is a captivating nightscape featuring a tranquil lake scene under a full moon and starry sky.\\xa0\\n\\n\\nHere's a breakdown of the elements:\\n\\n* **Sky:** A deep blue night sky dominates the upper two-thirds of the image, speckled with numerous stars and a bright, full moon positioned slightly off-center.\\n\\n* **Lake:** A calm, dark blue lake reflects the moon and the surrounding landscape perfectly, creating a mirror-like effect. The reflection is almost identical to the actual scene above.\\n\\n* **Landscape:** The lake is surrounded by a dark, dense forest of evergreen trees that climb a gently sloping mountain in the background. The silhouettes of the trees are sharply defined against the moonlit sky.\\n\\n* **Dock:** A wooden dock extends from the shore into the lake, acting as a central focal point leading the eye towards the moon. The dock is simple, made of weathered wood planks, with a modest railing on either side.  It appears to be connected to a slightly larger, platform-like structure in the middle of the lake.\\n\\n* **Foreground:** Tall grasses and vegetation line the shores of the lake, framing the dock and creating a natural border between the water and the land.\\xa0\\n\\n\\nThe overall mood is serene, peaceful, and slightly mystical. The contrast between the bright moon and stars, the dark silhouettes of the trees and mountains, and the calm, reflective water creates a visually stunning and evocative image. The composition is symmetrical and balanced, with the dock serving as the perfect axis.\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["to_markdown(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"RA6YbnOVY6Qu","executionInfo":{"status":"ok","timestamp":1744887413393,"user_tz":-330,"elapsed":4,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"8b18a502-e1dd-4af8-a2e9-b523aaa59682"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"> Here's a description of the image:\n> \n> The photograph is a captivating nightscape featuring a tranquil lake scene under a full moon and starry sky. \n> \n> \n> Here's a breakdown of the elements:\n> \n> * **Sky:** A deep blue night sky dominates the upper two-thirds of the image, speckled with numerous stars and a bright, full moon positioned slightly off-center.\n> \n> * **Lake:** A calm, dark blue lake reflects the moon and the surrounding landscape perfectly, creating a mirror-like effect. The reflection is almost identical to the actual scene above.\n> \n> * **Landscape:** The lake is surrounded by a dark, dense forest of evergreen trees that climb a gently sloping mountain in the background. The silhouettes of the trees are sharply defined against the moonlit sky.\n> \n> * **Dock:** A wooden dock extends from the shore into the lake, acting as a central focal point leading the eye towards the moon. The dock is simple, made of weathered wood planks, with a modest railing on either side.  It appears to be connected to a slightly larger, platform-like structure in the middle of the lake.\n> \n> * **Foreground:** Tall grasses and vegetation line the shores of the lake, framing the dock and creating a natural border between the water and the land. \n> \n> \n> The overall mood is serene, peaceful, and slightly mystical. The contrast between the bright moon and stars, the dark silhouettes of the trees and mountains, and the calm, reflective water creates a visually stunning and evocative image. The composition is symmetrical and balanced, with the dock serving as the perfect axis.\n"},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["response = model2.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about the journey meal\",img], stream=True)"],"metadata":{"id":"4MjEM6izZPlR","executionInfo":{"status":"ok","timestamp":1744887751698,"user_tz":-330,"elapsed":8314,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["response.resolve()"],"metadata":{"id":"1s3VvP00aLro","executionInfo":{"status":"ok","timestamp":1744887777517,"user_tz":-330,"elapsed":31,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["to_markdown(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":324},"id":"dlRR8waCaoeU","executionInfo":{"status":"ok","timestamp":1744887810623,"user_tz":-330,"elapsed":12,"user":{"displayName":"gaurav garwal","userId":"12951665473334985691"}},"outputId":"2c46958b-ef95-43e7-a320-26caf3c415c9"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"> ## Dinner Under the Stars: A Journey Meal to Remember\n> \n> The picture speaks for itself: tranquility personified. A long wooden dock stretches out over a still, dark lake, reflecting a breathtaking night sky illuminated by a full moon. Mountains loom in the distance, their silhouettes sharp against the star-studded canvas.  This isn't just a scene; it's the setting for an unforgettable meal.\n> \n> Forget Michelin stars and white tablecloths.  My journey meal that night was far simpler, yet infinitely more rewarding.  The \"table\" was the end of that very dock, the air cool and crisp with the scent of pine. The \"menu\"?  A hearty pot of chili, simmered over a crackling campfire earlier in the day, served in sturdy enamel mugs.  Simple, robust, and perfect for a night of quiet contemplation under the moon.\n> \n> The journey to this magical spot had been as rewarding as the destination itself. Hours of hiking through sun-dappled forests, the thrill of spotting wildlife along the trail, the anticipation building with every step closer to the lake.  The chili, warmed by the fire's embers, became a symbol of that journey – a culmination of effort, adventure, and a deep connection with nature.  Every bite tasted of the sun-kissed trails, the whispering trees, and the sheer wonder of the wilderness.\n> \n> This wasn't just dinner; it was a feast for the senses.  The taste of the chili, the cool night air, the breathtaking view – all combined to create a memory etched in my mind forever.  And it serves as a powerful reminder that sometimes, the simplest meals in the most extraordinary locations hold the most profound satisfaction. So, pack your bags, lace up your boots, and plan your next journey meal. You won't regret it.\n"},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":[],"metadata":{"id":"K0C7-vO1ary7"},"execution_count":null,"outputs":[]}]}